{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-20T01:35:47.836986Z",
     "start_time": "2024-12-20T01:35:47.831491Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "from typing import Tuple, List\n",
    "import time"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T01:35:47.859886Z",
     "start_time": "2024-12-20T01:35:47.848934Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class DataProcessor:\n",
    "    \"\"\"\n",
    "    Uma classe avançada para processamento de dados que demonstra uso sofisticado de métodos NumPy em cenários práticos.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, shape: Tuple[int, int], seed: int = 42):\n",
    "        \"\"\"\n",
    "        Inicializa o processador com um array de forma específica.\n",
    "\n",
    "        Args:\n",
    "            shape: Tupla definindo a forma do array (linhas, colunas)\n",
    "            seed: Semente para reprodutibilidade (padrão: 42)\n",
    "        \"\"\"\n",
    "        np.random.seed(seed)\n",
    "        self.data = np.random.rand(*shape)\n",
    "        self.original = self.data.copy()\n",
    "        self.processing_history = []\n",
    "\n",
    "    def sliding_window_processor(self, window_size: int = 3) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Processa dados usando uma janela deslizante e demonstrao uso avançado de views para otimização de memória.\n",
    "        \"\"\"\n",
    "        rows, cols = self.data.shape\n",
    "        result = np.zeros((rows - window_size + 1, cols - window_size + 1))\n",
    "\n",
    "        # Usando views para criar janelas deslizantes eficientes.\n",
    "        for i in range(rows - window_size + 1):\n",
    "            for j in range(cols - window_size + 1):\n",
    "                window = self.data[i:i+window_size, j:j+window_size].view()\n",
    "                result[i, j] = window.mean()\n",
    "\n",
    "        return result\n",
    "\n",
    "    def adaptive_thresholding(self, sensitivity: float = 1.0) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Aplica limiarização adaptativa usando diferentes métodos NumPy.\n",
    "        Demonstra uso avançado de copy() e fill().\n",
    "        \"\"\"\n",
    "        result = self.data.copy()\n",
    "\n",
    "        # Calcula estatísiticas locais\n",
    "        mean = np.mean(result)\n",
    "        std = np.std(result)\n",
    "\n",
    "        # Cria máscara adaptiva\n",
    "        mask = np.zeros_like(result)\n",
    "        mask.fill(mean)\n",
    "\n",
    "        # Aplica threshold adaptativo\n",
    "        threshold = mask + (std * sensitivity)\n",
    "        result[result < threshold] = 0\n",
    "\n",
    "        return result\n",
    "\n",
    "    def matrix_decompostion(self) -> Tuple[np.ndarray, List[float]]:\n",
    "        \"\"\"\n",
    "        Realiza decomposição de matriz usando diferentes views.\n",
    "        Demonstra uso avançado de tolist() e item().\n",
    "        \"\"\"\n",
    "        eigenvalues, eigenvectors = np.linalg.eig(self.data)\n",
    "\n",
    "        # Coverte eigenvalues para lista Python para processamento\n",
    "        eig_list = eigenvalues.tolist()\n",
    "\n",
    "        # Ordena os eigenvalue e mantém os índices\n",
    "        sorted_indices = np.argsort(eigenvalues)[::-1]\n",
    "\n",
    "        # Cria uma view dos eigenvectors ordenados\n",
    "        sorted_vectors = eigenvectors[:, sorted_indices].view()\n",
    "\n",
    "        # Extrai o primeiro eigenvalue como escalar\n",
    "        principal_component = sorted_vectors[:, 0]\n",
    "        principal_value = eigenvalues.item(sorted_indices[0])\n",
    "\n",
    "        return principal_component, eig_list\n",
    "\n",
    "    def process_with_memory_optimization(self, chunk_size: int=1000) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Processa grandes conjuntos de dados em chunks para otimização de memória.\n",
    "        Demonstra uso avançado de itemset() e view().\n",
    "        \"\"\"\n",
    "        rows, cols = self.data.shape\n",
    "        result = np.zeros_like(self.data)\n",
    "\n",
    "        for i in range(0, rows, chunk_size):\n",
    "            end_idx = min(i + chunk_size, rows)\n",
    "\n",
    "            # Processa um chunk por vez usando view\n",
    "            chunk = self.data[i:end_idx, :].view()\n",
    "            processed_chunk = np.exp(-chunk * chunk)\n",
    "\n",
    "            # Atualiza o resultado usando itemset para cada elemento\n",
    "            for r in range(chunk.shape[0]):\n",
    "                for c in range(cols):\n",
    "                    result.itemset((i+r, c), processed_chunk[r, c])\n",
    "\n",
    "        return result\n",
    "\n",
    "    def benchmark_operations(self) -> dict:\n",
    "        \"\"\"\n",
    "        Realiza o bechmark das diferentes operações e retorna métricas.\n",
    "        \"\"\"\n",
    "        metrics = {}\n",
    "\n",
    "        # Benchmark sliding window\n",
    "        start_time = time.time()\n",
    "        _ = self.sliding_window_processor()\n",
    "        metrics['sliding_window'] = time.time() - start_time\n",
    "\n",
    "        # Benchmark thresholding\n",
    "        start = time.time()\n",
    "        _ = self.adaptive_thresholding()\n",
    "        metrics['thresholding'] = time.time() - start\n",
    "\n",
    "        # Bechmark decompostion\n",
    "        start = time.time()\n",
    "        _ = self.matrix_decompostion()\n",
    "        metrics['decomposition'] = time.time() - start\n",
    "\n",
    "        return metrics"
   ],
   "id": "75e9b9bd9a92c23d",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T01:35:48.026388Z",
     "start_time": "2024-12-20T01:35:47.905455Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Exemplo de uso\n",
    "if __name__ == \"__main__\":\n",
    "    # Cria processador com matriz 100x100\n",
    "    processor = DataProcessor((100, 100))\n",
    "\n",
    "    # Executa processamentos\n",
    "    print(\"Processando dados...\")\n",
    "\n",
    "    # Aplica janela deslizante\n",
    "    window_result = processor.sliding_window_processor()\n",
    "    print(f'Forma do resultado da janela deslizante: {window_result.shape}')\n",
    "\n",
    "    # Aplica thresholding adaptativo\n",
    "    threshold_result = processor.adaptive_thresholding(sensitivity=1.2)\n",
    "    print(f'Valores únicos após thresholding: {np.unique(threshold_result).size}')\n",
    "\n",
    "    # Realiza decomposição\n",
    "    principal_comp, eigenvalues = processor.matrix_decompostion()\n",
    "    print(f'Primeiro autovalor: {eigenvalues[0]:.4f}')\n",
    "\n",
    "    # Executa benchmark\n",
    "    metrics = processor.benchmark_operations()\n",
    "    for operation, time_taken, in metrics.items():\n",
    "        print(f'{operation}: {time_taken:.4f} segundos')"
   ],
   "id": "333b90f662ecfc19",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processando dados...\n",
      "Forma do resultado da janela deslizante: (98, 98)\n",
      "Valores únicos após thresholding: 1545\n",
      "Primeiro autovalor: 49.4061+0.0000j\n",
      "sliding_window: 0.0533 segundos\n",
      "thresholding: 0.0002 segundos\n",
      "decomposition: 0.0083 segundos\n"
     ]
    }
   ],
   "execution_count": 15
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
